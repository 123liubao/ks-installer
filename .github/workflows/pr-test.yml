name: PR-Test

on:
  push:
    branches: [master, express]
  pull_request:
    branches: [master]

jobs:
  pr-test:
    runs-on: ubuntu-latest
    timeout-minutes: 150
    env:
      SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL_TEST }}
    steps:
    - uses: actions/checkout@v2

    - name: Build image
      run: docker build . --file Dockerfile --tag ks-installer

    - name: Create kind cluster
      uses: helm/kind-action@v1.0.0-rc.1

    - name: Load image to kind
      run: kind load docker-image ks-installer --name chart-testing

    - name: Deploy KubeSphere to Kind
      run: |
        kubectl apply -f deploy/kubesphere-installer.yaml
        kubectl apply -f deploy/cluster-configuration.yaml
        kubectl -n kubesphere-system get deploy ks-installer -oyaml | sed "s/imagePullPolicy: Always/imagePullPolicy: IfNotPresent/g" | kubectl replace -f -
        kubectl -n kubesphere-system set image deploy/ks-installer installer=ks-installer
        kubectl -n kubesphere-system get cc ks-installer -o yaml | sed "s/false/true/g" | kubectl replace -n kubesphere-system cc -f -
        kubectl -n kubesphere-system patch cc ks-installer --type merge --patch '{"spec":{"etcd":{"monitoring":false}}}'
        kubectl -n kubesphere-system patch cc ks-installer --type merge --patch '{"spec":{"etcd":{"tlsEnable":false}}}'
        kubectl -n kubesphere-system patch cc ks-installer --type merge --patch '{"spec":{"kubeedge":{"enabled":false}}}'
        kubectl -n kubesphere-system patch cc ks-installer --type merge --patch '{"spec":{"logging":{"enabled":false}}}'

    - name: Remove Abnormal Pods
      run: |
        # use kind to test, cannot find /etc/localtime for hostpath
        for i in {1..1200};do
          set +e
          kubectl -n kubesphere-logging-system get Ruler | grep ks-events-ruler
          if [[ $? -ne 0 ]];then
            sleep 1
            echo "wait $i s..."
            continue
          fi
          set -e
          kubectl -n kubesphere-logging-system delete Ruler ks-events-ruler
          break
        done

        for i in {1..1200};do
          set +e
          kubectl -n kubesphere-logging-system get Exporter | grep ks-events-exporter
          if [[ $? -ne 0 ]];then
            sleep 1
            echo "wait $i s..."
            continue
          fi
          set -e
          kubectl -n kubesphere-logging-system delete Exporter ks-events-exporter
          break
        done

        for i in {1..1200};do
          set +e
          kubectl -n kubesphere-system get job | grep openpitrix-import-job
          if [[ $? -ne 0 ]];then
            sleep 1
            echo "wait $i s..."
            continue
          fi
          set -e
          kubectl -n kubesphere-system delete job openpitrix-import-job
          break
        done

    - name: Adjust Mino Resource Request
      run: |
        for i in {1..1200};do
          set +e
          kubectl -n kubesphere-system get deploy | grep minio
          if [[ $? -ne 0 ]];then
            sleep 1
            echo "wait $i s..."
            continue
          fi
          set -e
          kubectl -n kubesphere-system get deploy minio -oyaml | sed '/cpu: /d' | sed '/memory: /d' | kubectl replace -f -
          break
        done

    - name: Adjust Prometheus Resource Request
      run: |
        for i in {1..900};do
          set +e
          kubectl -n kubesphere-monitoring-system get deploy | grep prometheus-operator
          if [[ $? -ne 0 ]];then
            sleep 1
            echo "wait $i s..."
            continue
          fi
          set -e
          sleep 2
          kubectl -n kubesphere-monitoring-system get deploy prometheus-operator -oyaml | sed '/cpu: /d' | sed '/memory: /d' | kubectl replace -f -
          break
        done

    - name: Adjust servicemesh Resource Request
      run: |
        for i in {1..1200};do
          set +e
          kubectl -n istio-system get deploy | grep istiod
          if [[ $? -ne 0 ]];then
            sleep 1
            echo "wait $i s..."
            continue
          fi
          set -e
          sleep 2
          kubectl -n istio-system get deploy istiod-1-6-10 -oyaml | sed '/cpu: /d' | sed '/memory: /d' | kubectl replace -f -
          break
        done

        for i in {1..1200};do
          set +e
          kubectl -n istio-system get deploy | grep istio-ingressgateway
          if [[ $? -ne 0 ]];then
            sleep 1
            echo "wait $i s..."
            continue
          fi
          set -e
          sleep 2
          kubectl -n istio-system get deploy istio-ingressgateway -oyaml | sed '/cpu: /d' | sed '/memory: /d' | kubectl replace -f -
          break
        done

    - name: Adjust Devops Resource Request
      run: |
        for i in {1..1200};do
          set +e
          kubectl -n kubesphere-devops-system get deploy | grep ks-jenkins
          if [[ $? -ne 0 ]];then
            sleep 1
            echo "wait $i s..."
            continue
          fi
          set -e
          sleep 2
          kubectl -n kubesphere-devops-system get deploy ks-jenkins -oyaml | sed '/cpu: /d' | sed '/memory: /d' | kubectl replace -f -
          break
        done

    - name: Adjust Prometheus-k8s Resource Request
      run: |
        for i in {1..900};do
          set +e
          kubectl -n kubesphere-monitoring-system get sts | grep prometheus-k8s
          if [[ $? -ne 0 ]];then
            sleep 1
            echo "wait $i s..."
            continue
          fi
          set -e
          sleep 2
          kubectl -n kubesphere-monitoring-system get sts prometheus-k8s -oyaml | sed '/cpu: /d' | sed '/memory: /d' | kubectl replace -f -
          break
        done

    - name: Check Cluster Status
      run: bash scripts/check_cluster_status.sh
      timeout-minutes: 90

    - name: slack
      uses: 8398a7/action-slack@v3
      with:
        status: ${{ job.status }}
        fields: repo,message,commit,author,action,eventName,ref,workflow,job,took
      if: ${{ failure() }}
